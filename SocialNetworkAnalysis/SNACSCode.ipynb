{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read a social graph and preprocess it in such a way that it can be compressed\n",
        "using the WebGraph method.\n",
        "\"\"\"\n",
        "# NOTE: unsure if we can improve memory management by freeing memory or if\n",
        "# python does this by itself.\n",
        "\n",
        "import requests  # read social graph from web\n",
        "import gzip\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "\n",
        "\n",
        "# -1: none, 0: size, 1: modularity contribution, 2: edge density, 3: edge count\n",
        "#COMM_SORTING = 0\n",
        "# -1: none, 0: outdegree, 1: indegree, 2: betweenness, 3: pagerank, 4: closeness\n",
        "#NODE_SORTING = 0\n",
        "# -1: none, 0: BFS, 1: DFS\n",
        "#SEARCH = -1\n",
        "\n",
        "\n",
        "# ====== COMMUNITY SORTING METHODS ======\n",
        "def community_sort_by_size(communities, subgraphs):\n",
        "    sorted_communities = sorted(subgraphs, key=len, reverse=True)\n",
        "\n",
        "\n",
        "    print(f\"Found {communities} communities with largest community of\"\n",
        "          f\" size {len(sorted_communities[0])} and smallest community of size \"\n",
        "          f\" {len(sorted_communities[-1])}\")\n",
        "    return sorted_communities\n",
        "\n",
        "\n",
        "def community_sort_by_modularity_contribution(communities, subgraphs):\n",
        "    sorted_c = sorted(subgraphs, key=lambda x:\n",
        "                      nx.community.modularity(x, [x.nodes()]),\n",
        "                      reverse=True)\n",
        "\n",
        "    print(f\"Found {communities} communities with highest modularity\"\n",
        "          f\" contribution \"\n",
        "          f\" {nx.community.modularity(sorted_c[0], [sorted_c[0].nodes()])} and\"\n",
        "          f\" smallest modularity contribution \"\n",
        "          f\" {nx.community.modularity(sorted_c[-1], [sorted_c[-1].nodes()])}\")\n",
        "    return sorted_c\n",
        "\n",
        "\n",
        "def community_sort_by_edge_density(communities, subgraphs):\n",
        "    sorted_communities = sorted(subgraphs, key=lambda x: nx.density(x),\n",
        "                                reverse=True)\n",
        "    print(f\"Found {communities} communities with highest density\"\n",
        "          f\" {nx.density(sorted_communities[1])} and smallest density\"\n",
        "          f\" {nx.density(sorted_communities[-1])}\")\n",
        "    return sorted_communities\n",
        "\n",
        "\n",
        "def community_sort_by_edge_count(communities, subgraphs):\n",
        "    sorted_communities = sorted(subgraphs, key=lambda x: x.number_of_edges(),\n",
        "                                reverse=True)\n",
        "    print(f\"Found {communities} communities with highest edge count\"\n",
        "          f\" {nx.density(sorted_communities[1])} and smallest edge count\"\n",
        "          f\" {nx.density(sorted_communities[-1])}\")\n",
        "    return sorted_communities\n",
        "\n",
        "\n",
        "def community_sort_by_nothing(communities, subgraphs):\n",
        "    return subgraphs\n",
        "\n",
        "\n",
        "community_sort = [\n",
        "    community_sort_by_size,\n",
        "    community_sort_by_modularity_contribution,\n",
        "    community_sort_by_edge_density,\n",
        "    community_sort_by_edge_count,\n",
        "    community_sort_by_nothing\n",
        "]\n",
        "\n",
        "\n",
        "# ====== NODE SORTING METHODS ======\n",
        "def node_sort_by_outdegree(C):\n",
        "    sorted_nodes = sorted(C.nodes, key=lambda x: C.out_degree(x), reverse=True)\n",
        "    return sorted_nodes\n",
        "\n",
        "\n",
        "def node_sort_by_indegree(C):\n",
        "    sorted_nodes = sorted(C.nodes, key=lambda x: C.in_degree(x), reverse=True)\n",
        "    return sorted_nodes\n",
        "\n",
        "\n",
        "\n",
        "def node_sort_by_nothing(C):\n",
        "    return list(C.nodes)\n",
        "\n",
        "\n",
        "node_sort = [\n",
        "    node_sort_by_outdegree,\n",
        "    node_sort_by_indegree,\n",
        "    node_sort_by_nothing\n",
        "]\n",
        "\n",
        "\n",
        "# ====== NODE RELABELLING ======\n",
        "def bfs(C, sorted_nodes):\n",
        "    visited = set()\n",
        "    bfs_order = []\n",
        "\n",
        "    #deque to efficiently pop first element O(1) compared to O(n) for a normal list\n",
        "    queue = deque()\n",
        "\n",
        "    #precompute indices\n",
        "    node_index = {node: i for i, node in enumerate(sorted_nodes)}\n",
        "\n",
        "    # make sure all nodes are visited\n",
        "    for node in sorted_nodes:\n",
        "        if node not in visited:\n",
        "            queue.append(node)\n",
        "        while queue:\n",
        "        # sort successors based on sorted_nodes\n",
        "          current = queue.popleft()\n",
        "          if current not in visited:\n",
        "              visited.add(current)\n",
        "              bfs_order.append(current)\n",
        "              nb = sorted(C.successors(current),key=lambda x: node_index[x])\n",
        "              queue.extend(nb)\n",
        "\n",
        "\n",
        "    return bfs_order\n",
        "\n",
        "\n",
        "def dfs(C, sorted_nodes):\n",
        "    visited = set()\n",
        "    dfs_order = []\n",
        "    stack = []\n",
        "\n",
        "    #precompute indices\n",
        "    node_index = {node: i for i, node in enumerate(sorted_nodes)}\n",
        "\n",
        "    # make sure all nodes are visited\n",
        "    for node in sorted_nodes:\n",
        "        if node not in visited:\n",
        "            stack.append(node)\n",
        "            while stack:\n",
        "                current = stack.pop()\n",
        "                if current not in visited:\n",
        "                    visited.add(current)\n",
        "                    dfs_order.append(current)\n",
        "                    nb = sorted(C.successors(current),key=lambda x: node_index[x])\n",
        "                    stack.extend(nb)\n",
        "    return dfs_order\n",
        "\n",
        "def no_order(C,sorted_nodes):\n",
        "  return sorted_nodes\n",
        "\n",
        "order_nodes = [bfs, dfs,no_order]\n",
        "\n",
        "\n",
        "# ====== GAP DISTRIBUTION ======\n",
        "def compute_gap_distribution(G):\n",
        "    gap_distribution = Counter()\n",
        "\n",
        "    for node in G.nodes:\n",
        "        nb = sorted(G.successors(node))\n",
        "        if len(nb) > 1:\n",
        "            gaps = [nb[i] - nb[i - 1] for i in range(1, len(nb))]\n",
        "            gap_distribution.update(gaps)\n",
        "    return gap_distribution\n",
        "\n",
        "\n",
        "def plot_gap_distribution(gap_distribution,graph_name,c,n,s):\n",
        "    gap_sizes = np.array(list(gap_distribution.keys()))\n",
        "    frequencies = np.array(list(gap_distribution.values()))\n",
        "    probabilities = frequencies / np.sum(frequencies)\n",
        "    sorted_indices = np.argsort(gap_sizes)\n",
        "    gap_sizes = gap_sizes[sorted_indices]\n",
        "    probabilities = probabilities[sorted_indices]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.loglog(gap_sizes, probabilities, 'o', color='black',\n",
        "               markersize=3, alpha=0.7, label='Gap distribution')\n",
        "    plt.xlabel('Gap Size (log scale)')\n",
        "    plt.ylabel('Probability Density (log scale)')\n",
        "    plt.title('gap distribution')\n",
        "    plt.savefig(f\"{graph_name}{c}{n}{s}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "#Export to adjacency list .graph-txt\n",
        "def export(G,graph_name,c,n,s):\n",
        "    with open(f\"{graph_name}{c}{n}{s}.graph-txt\", \"w\") as f:\n",
        "        f.write(f'{G.number_of_nodes()}\\n')\n",
        "        for i in nx.generate_adjlist(G):\n",
        "            f.write(\" \".join(map(str, sorted(map(int, i.split()[1:])))))\n",
        "            f.write('\\n')\n",
        "\n",
        "\n",
        "# ====== MAIN ======\n",
        "# URL of zipped source data file\n",
        "#urls = [\"https://snap.stanford.edu/data/soc-Slashdot0902.txt.gz\",\"https://networks.skewed.de/net/prosper/files/prosper.csv.zip\",\"https://networks.skewed.de/net/flickr_aminer/files/flickr_aminer.csv.zip\"]\n",
        "#url = \"https://snap.stanford.edu/data/soc-Slashdot0902.txt.gz\"\n",
        "#url = \"https://networks.skewed.de/net/flickr_aminer/files/flickr_aminer.csv.zip\"\n",
        "#url = \"https://networks.skewed.de/net/prosper/files/prosper.csv.zip\"\n",
        "\n",
        "#Function to generate the different orderings\n",
        "def main_generation(url,graph_name):\n",
        "  ok = False\n",
        "  if url.endswith(\".gz\"):\n",
        "    # fetch file\n",
        "    # NOTE: stream=True reads the file in chunks\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # load graph\n",
        "        ok = True\n",
        "        G = nx.DiGraph()\n",
        "\n",
        "        # decompress data\n",
        "        with gzip.GzipFile(fileobj=response.raw) as gz:\n",
        "            for line in gz.read().decode('utf-8').splitlines():\n",
        "                if line.startswith('#'):\n",
        "                    continue\n",
        "                source, target = map(int, line.split())\n",
        "                G.add_edge(source, target)\n",
        "\n",
        "\n",
        "  elif url.endswith(\".zip\"): #files from https://networks.skewed.de/ zip with 3 files, we want edges.csv\n",
        "      response = requests.get(url, stream=True)\n",
        "      if response.status_code == 200:\n",
        "        # load graph\n",
        "        ok = True\n",
        "\n",
        "        # decompress data\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
        "          # Check if edges.csv is in the zip\n",
        "          if \"edges.csv\" not in zip_file.namelist():\n",
        "              raise ValueError(f\"File edges.csv not found in the ZIP archive.\")\n",
        "\n",
        "          # Open the CSV file directly and load it into a DataFrame\n",
        "          with zip_file.open(\"edges.csv\") as csv:\n",
        "            df = pd.read_csv(csv,skiprows=1,header=None,usecols=[0,1])\n",
        "            G = nx.from_pandas_edgelist(df,0,1,create_using=nx.DiGraph())\n",
        "\n",
        "  print(f\"Graph loaded with {G.number_of_nodes()} nodes \"\n",
        "        f\"and {G.number_of_edges()} edges\")\n",
        "  if ok:\n",
        "      # community processing\n",
        "      communities = nx.community.louvain_communities(G)\n",
        "      communities_len = len(communities)\n",
        "      subgraphs = []\n",
        "      while communities:\n",
        "      # Delete communities dinamically\n",
        "        community = communities.pop(0)\n",
        "        subgraphs.append(G.subgraph(community))\n",
        "\n",
        "      #free some ram\n",
        "      del communities\n",
        "\n",
        "      for comm_s in range(-1,4):\n",
        "        sorted_communities = community_sort[comm_s](communities_len,subgraphs)\n",
        "\n",
        "        for node_s in range(-1,2):\n",
        "          for search in range(-1,2):\n",
        "            # node processing\n",
        "            relabel_map = {}\n",
        "            new_label = 0\n",
        "            for C in sorted_communities:\n",
        "                sorted_nodes = node_sort[node_s](C)\n",
        "                order = order_nodes[search](C, sorted_nodes)\n",
        "                # relabel nodes\n",
        "                for node in order:\n",
        "                    relabel_map[node] = new_label\n",
        "                    new_label += 1\n",
        "\n",
        "            # relabel graph\n",
        "            G_relabelled = nx.relabel_nodes(G, relabel_map)\n",
        "\n",
        "            # plot gap distr\n",
        "            gap_distr = compute_gap_distribution(G_relabelled)\n",
        "            plot_gap_distribution(gap_distr,graph_name,comm_s,node_s,search)\n",
        "\n",
        "            # store new graph as adj list\n",
        "            export(G_relabelled,graph_name,comm_s,node_s,search)\n",
        "  else:\n",
        "      print(f\"Failed to fetch file. Status Code: {response.status_code}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "   urls = [\"https://snap.stanford.edu/data/soc-Slashdot0902.txt.gz\",\"https://networks.skewed.de/net/prosper/files/prosper.csv.zip\",\"https://networks.skewed.de/net/flickr_aminer/files/flickr_aminer.csv.zip\"]\n",
        "   names = ['slash','prosper','flickr']\n",
        "   for url,name in zip(urls,names):\n",
        "      main_generation(url,name)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMRzshKRaAyf",
        "outputId": "c0edbdf6-a100-4ce3-f160-0b7a926d4187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph loaded with 82168 nodes and 948464 edges\n",
            "Found 1014 communities with largest community of size 18263 and smallest community of size  2\n",
            "Found 1014 communities with highest modularity contribution  1.1102230246251565e-16 and smallest modularity contribution  0.0\n",
            "Found 1014 communities with highest density 2.0 and smallest density 0.0005258412547083613\n",
            "Found 1014 communities with highest edge count 0.0010332122240658877 and smallest edge count 1.0\n",
            "Graph loaded with 89269 nodes and 3330225 edges\n",
            "Found 51 communities with largest community of size 27112 and smallest community of size  2\n",
            "Found 51 communities with highest modularity contribution  1.1102230246251565e-16 and smallest modularity contribution  0.0\n",
            "Found 51 communities with highest density 0.5 and smallest density 0.0007468748714004073\n",
            "Found 51 communities with highest edge count 0.0007468748714004073 and smallest edge count 0.5\n",
            "Graph loaded with 214626 nodes and 9114557 edges\n",
            "Found 172 communities with largest community of size 71355 and smallest community of size  2\n",
            "Found 172 communities with highest modularity contribution  1.1102230246251565e-16 and smallest modularity contribution  0.0\n",
            "Found 172 communities with highest density 0.5 and smallest density 0.00020732010696639086\n",
            "Found 172 communities with highest edge count 0.005452966147502898 and smallest edge count 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_zip_name(name):\n",
        "  zip_file = zipfile.ZipFile(f'session_files_{name}.zip', 'w')\n",
        "  for root, dirs, files in os.walk('/content'):\n",
        "      for file in files:\n",
        "        if(file.startswith(f'{name}')):\n",
        "          zip_file.write(os.path.join(root, file))\n",
        "  zip_file.close()\n",
        "\n",
        "create_zip_name('prosper')"
      ],
      "metadata": {
        "id": "mZOVJkaYO394"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_zips_all_names():\n",
        "  names = ['slash','flickr','prosper']\n",
        "  for name in names:\n",
        "    zip_file = zipfile.ZipFile(f'session_files_{name}.zip', 'w')\n",
        "    for root, dirs, files in os.walk('/content'):\n",
        "        for file in files:\n",
        "          if(file.startswith(f'{name}')):\n",
        "            zip_file.write(os.path.join(root, file))\n",
        "    zip_file.close()\n",
        "\n",
        "create_zips_all_names()"
      ],
      "metadata": {
        "id": "c6rNm5qvuTaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ignore spaghetti below here"
      ],
      "metadata": {
        "id": "EwfGrnU_geAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "w1x2bbk1UL3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.read_edgelist(\"Slashdot0902.txt\",create_using=nx.DiGraph)\n",
        "print(f'Edges: {G.number_of_edges()}')\n",
        "print(f'Nodes: {G.number_of_nodes()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0BOMwFub1lJ",
        "outputId": "3f070769-0236-4e86-a6a2-d09ebc23de3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edges: 948464\n",
            "Nodes: 82168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_edges = G.number_of_edges()"
      ],
      "metadata": {
        "id": "bSM9cdHW0y_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sort communities by size"
      ],
      "metadata": {
        "id": "_PuazUAK3F7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "communities = nx.community.louvain_communities(G)"
      ],
      "metadata": {
        "id": "iCdQQfdOXed1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_communities_size = sorted(communities, key=len, reverse=True)"
      ],
      "metadata": {
        "id": "y7lClIcgnj1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_communities_size = nx.DiGraph()\n",
        "\n",
        "for community in sorted_communities_size:\n",
        "    for node in community:\n",
        "        G_communities_size.add_node(node)\n",
        "\n",
        "G_communities_size.add_edges_from(G.edges)"
      ],
      "metadata": {
        "id": "Sgas8qoKo_ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_adj(G,file):\n",
        "  with open(f\"{file}.graph-txt\", \"w\") as f:\n",
        "    f.write(str(G.number_of_nodes())+'\\n')\n",
        "    for i in nx.generate_adjlist(G):\n",
        "      f.write(\" \".join(map(str, sorted(map(int, i.split()[1:])))))\n",
        "      f.write('\\n')\n",
        "  print(f'{file}.graph-txt created')"
      ],
      "metadata": {
        "id": "W4mwnI563UZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_adj(G_communities_size,'communities_size')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh-on47T3TLm",
        "outputId": "1ded2af8-2ea7-49ea-f2c3-30fefc8e7502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "communities_size.graph-txt created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JsPCDzpDLp1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sort communities by modularity contribution and nodes within communities by outdegree"
      ],
      "metadata": {
        "id": "wJWJ6bRCCRMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modularity_contribution(G,community,total_edges):\n",
        "    edges_inside = community.number_of_edges()\n",
        "    degree_community_sum = sum(G.degree(n) for n in community.nodes)\n",
        "    return edges_inside / total_edges - (degree_community_sum / (2 * total_edges)) ** 2"
      ],
      "metadata": {
        "id": "T2_JHR4pxuwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "communities_modularity = nx.community.modularity(G, communities)\n",
        "communities_modularity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrk936e71DEk",
        "outputId": "963d0099-113a-4904-c019-b7d3eb70f559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3965203557855198"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_communities_mod(G,communities):\n",
        "  community_modularities = []\n",
        "  for community in communities:\n",
        "      community_modularities.append(modularity_contribution(G,G.subgraph(community),total_edges))\n",
        "\n",
        "\n",
        "  communities_modularity_zip = list(zip(communities,community_modularities))\n",
        "  sorted_communities_modularity = sorted(communities_modularity_zip,key=lambda x: x[1],reverse=True)\n",
        "  sorted_communities_modularity = [c for c,m in sorted_communities_modularity]\n",
        "  return sorted_communities_modularity"
      ],
      "metadata": {
        "id": "F5lNxQ9gWPSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "community_modularities = []\n",
        "for community in communities:\n",
        "    community_modularities.append(modularity_contribution(G.subgraph(community),total_edges))\n",
        "\n",
        "\n",
        "communities_modularity_zip = list(zip(communities,community_modularities))\n",
        "sorted_communities_modularity = sorted(communities_modularity_zip,key=lambda x: x[1],reverse=True)\n",
        "sorted_communities_modularity = [c for c,m in sorted_communities_modularity]\n"
      ],
      "metadata": {
        "id": "XTfgKi7Foump"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(community_modularities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71jbJoGfGy3N",
        "outputId": "3db0a6ca-99da-4bc2-fefd-1c768ab16c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3965181224153244"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_nodes_degree(G,communities_ordered):\n",
        "  sorted_nodes = []\n",
        "  for c in communities_ordered:\n",
        "      for n in sorted(c, key=lambda node: G.out_degree(node), reverse=True):\n",
        "        sorted_nodes.append(n)\n",
        "  return sorted_nodes\n"
      ],
      "metadata": {
        "id": "nuC7PiCc8B2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_nodes_mod_degree = sort_nodes_degree(sorted_communities_modularity)\n"
      ],
      "metadata": {
        "id": "DpFpOIQf7rrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_mod_deg = nx.DiGraph()\n",
        "G_mod_deg.add_nodes_from(sorted_nodes_mod_degree)\n",
        "G_mod_deg.add_edges_from(G.edges)\n"
      ],
      "metadata": {
        "id": "PFfrrcFuCa62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_adj(G_mod_deg,\"mod_outdegree\")"
      ],
      "metadata": {
        "id": "8ExouwyoFEi6",
        "outputId": "9e9e1836-7d3a-4474-adae-5eead631cc38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mod_outdegree.graph-txt created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sort communities by clustering coefficient"
      ],
      "metadata": {
        "id": "dCgKaDIxMCfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clustering_coeffs = []\n",
        "for community in communities:\n",
        "  subgraph = G.subgraph(community)\n",
        "  clustering_coeffs.append(nx.average_clustering(subgraph))\n"
      ],
      "metadata": {
        "id": "OjX5IhKMMCDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "communities_modularity_zip = list(zip(communities,clustering_coeffs))\n",
        "sorted_communities_clustering = sorted(communities_modularity_zip,key=lambda x: x[1],reverse=True)\n",
        "sorted_communities_clustering = [c for c,m in sorted_communities_clustering]"
      ],
      "metadata": {
        "id": "gbT33jYYR6Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_clustering = nx.DiGraph()\n",
        "\n",
        "for community in sorted_communities_clustering:\n",
        "    for node in community:\n",
        "        G_clustering.add_node(node)\n",
        "G_clustering.add_edges_from(G.edges)\n"
      ],
      "metadata": {
        "id": "y9SmT7blVmI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_adj(G_clustering,\"clustering\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmVtXbQlV8dd",
        "outputId": "3f51b930-0c08-4948-feba-2504945cec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clustering.graph-txt created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "ognB5NqY1A8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/network.csv.zip'\n",
        "try:\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        extract_path = '/content/data'\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "        zip_ref.extractall(extract_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: Invalid zip file at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "KA5m77IR05CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/edges.csv',skiprows=1,header=None,usecols=[0,1])\n",
        "G_prosper = nx.from_pandas_edgelist(df,0,1,create_using=nx.DiGraph())"
      ],
      "metadata": {
        "id": "zSk47DGY1oaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Edges: {G_prosper.number_of_edges()}')\n",
        "print(f'Nodes: {G_prosper.number_of_nodes()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZLqAvZqVLFc",
        "outputId": "f1e54f40-52bf-4af4-8ee9-39787139d581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edges: 3330225\n",
            "Nodes: 89269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_edges = G_prosper.number_of_edges()"
      ],
      "metadata": {
        "id": "A93rXMsXf2DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "communities = nx.community.louvain_communities(G_prosper)"
      ],
      "metadata": {
        "id": "n2Uv9z23Vb3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_communities_size = sorted(communities, key=len, reverse=True)"
      ],
      "metadata": {
        "id": "x2NylGi55wCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_prosper_communities_size = nx.DiGraph()\n",
        "\n",
        "for community in sorted_communities_size:\n",
        "    for node in community:\n",
        "        G_prosper_communities_size.add_node(node)\n",
        "\n",
        "G_prosper_communities_size.add_edges_from(G_prosper.edges)"
      ],
      "metadata": {
        "id": "P6juE4r952VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_adj(G_prosper_communities_size,'prosper_communities_size')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0i4iNZ-5_ML",
        "outputId": "b4b1435f-39d3-4f7f-fd1b-b21b786a317b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prosper_communities_size.graph-txt created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_communities_modularity = sort_communities_mod(G_prosper,communities)"
      ],
      "metadata": {
        "id": "znFTuvjzWbIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_prosper_communities_mod = nx.DiGraph()\n",
        "\n",
        "for community in sorted_communities_size:\n",
        "    for node in community:\n",
        "        G_prosper_communities_mod.add_node(node)\n",
        "\n",
        "G_prosper_communities_mod.add_edges_from(G_prosper.edges)"
      ],
      "metadata": {
        "id": "w1Y0Lcbm7Dy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_adj(G_prosper_communities_size,'prosper_communities_mod')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff7F3s1s7XTu",
        "outputId": "b26524b5-8798-43a9-a79c-85d8ddb32870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prosper_communities_mod.graph-txt created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_nodes_mod_degree = sort_nodes_degree(G_prosper,sorted_communities_modularity)"
      ],
      "metadata": {
        "id": "NBqji-3f46at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_prosper_mod_deg = nx.DiGraph()\n",
        "G_prosper_mod_deg.add_nodes_from(sorted_nodes_mod_degree)\n",
        "G_prosper_mod_deg.add_edges_from(G_prosper.edges)"
      ],
      "metadata": {
        "id": "f6mw-nSa5dSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_adj(G_prosper_mod_deg,'prosper_mod_deg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBT51-7f6P0R",
        "outputId": "304582a9-8408-4c82-cbd1-4084bdec5aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prosper_mod_deg.graph-txt created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/network.csvflicker.zip'\n",
        "try:\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        extract_path = '/content/data'\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "        zip_ref.extractall(extract_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: Invalid zip file at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "y7LoRB589-yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/edges.csv',skiprows=1,header=None,usecols=[0,1])\n",
        "G_flicker = nx.from_pandas_edgelist(df,0,1,create_using=nx.DiGraph())"
      ],
      "metadata": {
        "id": "Z_wXHOtq-d0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Edges: {G_flicker.number_of_edges()}')\n",
        "print(f'Nodes: {G_flicker.number_of_nodes()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbmZ1c_r-iSe",
        "outputId": "0a65dfd9-ba96-4570-e6c5-d719e6f4d8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edges: 9114557\n",
            "Nodes: 214626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_edges = G_flicker.number_of_edges()"
      ],
      "metadata": {
        "id": "59pljKK9-m6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "communities = nx.community.louvain_communities(G_flicker)"
      ],
      "metadata": {
        "id": "0g066JVE-odM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_communities_modularity = sort_communities_mod(G_flicker,communities)"
      ],
      "metadata": {
        "id": "1TUELavl-qFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_nodes_mod_degree = sort_nodes_degree(G_flicker,sorted_communities_modularity)"
      ],
      "metadata": {
        "id": "blOF2FvF-r4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_flicker_mod_deg = nx.DiGraph()\n",
        "G_flicker_mod_deg.add_nodes_from(sorted_nodes_mod_degree)\n",
        "G_flicker_mod_deg.add_edges_from(G_flicker.edges)"
      ],
      "metadata": {
        "id": "fuOWkv9L-1AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_adj(G_flicker_mod_deg,'flicker_mod_deg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_GK4ftA_QC1",
        "outputId": "a6e1351f-31ee-44df-a6b7-2b530e4a1b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flicker_mod_deg.graph-txt created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comments from the code review session"
      ],
      "metadata": {
        "id": "dhDF9wKfPIkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. When plotting the graphs, you were wondering why the previous graphs were disepearing. Maybe it is because plt.close() is called at the end of the function. This closes the figure after saving it, ensuring that it doesn't stay in memory. This behavior is intentional and is used to free up resources in a script that generates multiple plots. However, it also means that the figure is no longer accessible for further inspection or interaction."
      ],
      "metadata": {
        "id": "GrXvNXwTPQfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code is readable.\n",
        "It is a good idea to plot the gap distributions.\n",
        "The part where you test the functions is well organized, but the part where you define them needs a little bit of cleaning (divide the code into different cells).  \n",
        "More comments are needed to explain the code.\n"
      ],
      "metadata": {
        "id": "gFyBXbwwUvGm"
      }
    }
  ]
}